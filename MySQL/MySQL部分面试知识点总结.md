# 面试时问到的MySQL相关的我有点模糊的问题

# 1、索引相关问题

## 1.1、MySQL有哪些索引

**MySQL的索引包括普通索引、唯一性索引、全文索引、单列索引、多列索引和空间索引等。**

- 从 **功能逻辑** 上说，索引主要有 4 种，分别是普通索引、唯一索引、主键索引、全文索引。

- 按照 **物理实现方式** ，索引可以分为 2 种：聚簇索引和非聚簇索引。

- 按照 **作用字段个数** 进行划分，分成单列索引和联合索引。

> 通过询问AI认识到，外键和索引是两个概念，外键是一种约束，只是InnoDB在创建外键的时候会自动建立索引，避免全表扫描验证约束，MyISAM则不会自动创建。
>
> - **外键是约束（Constraint）** ，而非索引类型。它的核心功能是**维护数据完整性**（Referential Integrity），确保子表（Child Table）中某列的值必须在父表（Parent Table）的对应列中存在。
> - 外键依赖索引：
>   - 父表的被引用列**必须为主键或唯一索引**（否则无法创建外键）。
>   - 子表的外键列**可能自动生成索引**（取决于存储引擎）：
> - **InnoDB**：自动为子表的外键列创建索引（避免全表扫描验证约束）。
> - **MyISAM**：不会自动创建索引，需手动添加。



## 1.2、B+树比较B树的优势

①B+树查询效率更稳定。因为B树在根节点也存数据，查询次数不稳定。

②B+树查询效率一般更高。一般来说，B+树更矮胖，查询次数少。

③在范围查询上，B+树比B树效率更高，这一点也是因为B+树只在叶子结点存数据。

④B+树磁盘读写代价更低，因为他的节点不存放数据，可以存放的索引量更大



## 1.3、Hash索引对比B+树索引的劣势

①无序，不支持Order By等查询操作

②不支持范围查找

③不支持联合索引的最左侧原则。联合索引必须完整对应才能使用，不能只用前几个，因为他是把整个联合索引一起hash然后进行映射的

④重复项较多的时候效率低，因为重复项一般使用链表结构保存

⑤无法使用Hash索引进行模糊查询





# 2、数据库设计与调优问题

## 2.1、为什么不用自增主键/自增主键的问题

自增ID做主键，简单易懂，几乎所有数据库都支持自增类型，只是实现上各自有所不同而已。

自增ID除 了简单，其他都是缺点，总体来看存在以下几方面的问题：

1. **可靠性不高**

   存在自增ID回溯的问题，这个问题直到最新版本的MySQL 8.0才修复。 

2. **安全性不高 **

   对外暴露的接口可以非常容易猜测对应的信息。比如：/User/1/这样的接口，可以非常容易猜测用户ID的 值为多少，总用户数量有多少，也可以非常容易地通过接口进行数据的爬取。 

3. **性能差** 

   自增ID的性能较差，需要在数据库服务器端生成。 

4. **交互多** 

   业务还需要额外执行一次类似 last_insert_id() 的函数才能知道刚才插入的自增值，这需要多一次的 网络交互。在海量并发的系统中，多1条SQL，就多一次性能上的开销。 

5. **局部唯一性 **

   **最重要的一点，自增ID是局部唯一**，只在当前数据库实例中唯一，而不是全局唯一，在任意服务器间都 是唯一的。对于目前分布式系统来说，这简直就是噩梦。

> 在MySQL 8.0之前，由于自增ID的计数器存储在内存中，重启数据库后可能导致ID不连续。同时，在并发事务中，为了避免冲突，MySQL会对申请的自增值加锁，并按顺序分配。如果事务回滚，可能会导致ID冲突。
>
> 从MySQL 8.0开始，通过将自增ID持久化并引入自增锁机制，解决了重启后ID重复利用的问题，并保证了ID的连续性。尽管如此，自增主键还是有很多劣势不推荐使用，尤其是他是局部唯一的而非全局唯一。

> 可以使用 美团开源的微服务全局ID中间件是Leaf

> 可以参考类似UUID的 “时间 + 去重字段 + 用户标识 ” 的形式设计主键，保证全局唯一性。
>
> **注意：UUID默认是无序的，具体与其设计有关，但是MySQL 8.0可以将UUID转换为有序的形式。**
>
> ```txt
> UUID = 时间+UUID版本（16字节）- 时钟序列（4字节） - MAC地址（12字节）
> ```
>
> MySQL 8.0针对UUID的优化：
>
> 我们以UUID值e0ea12d4-6473-11eb-943c-00155dbaa39d举例：
>
> ![image-20220706162131362](http://jason243.online/DatabasesNote/MySQL/codinglin_mysql_notes/MySQL%E7%B4%A2%E5%BC%95%E5%8F%8A%E8%B0%83%E4%BC%98%E7%AF%87.assets/image-20220706162131362.png)
>
> `为什么UUID是全局唯一的？`
>
> 在UUID中时间部分占用60位，存储的类似TIMESTAMP的时间戳，但表示的是从1582-10-15 00：00：00.00 到现在的100ns的计数。可以看到UUID存储的时间精度比TIMESTAMPE更高，时间维度发生重复的概率降 低到1/100ns。
>
> 时钟序列是为了避免时钟被回拨导致产生时间重复的可能性。MAC地址用于全局唯一。
>
> `为什么UUID占用36个字节？`
>
> UUID根据字符串进行存储，设计时还带有无用"-"字符串，因此总共需要36个字节。
>
> `为什么UUID是随机无序的呢？`
>
> 因为UUID的设计中，将时间低位放在最前面，而这部分的数据是一直在变化的，并且是无序。
>
> **改造UUID**
>
> 若将时间高低位互换，则时间就是单调递增的了，也就变得单调递增了。MySQL 8.0可以更换时间低位和时间高位的存储方式，这样UUID就是有序的UUID了。
>
> MySQL 8.0还解决了UUID存在的空间占用的问题，除去了UUID字符串中无意义的"-"字符串，并且将字符串用二进制类型保存，这样存储空间降低为了16字节。



## 2.2、数据库的六种设计范式

数据库设计中的六种范式是关系数据库设计的重要理论基础，它们分别是：

- **第一范式（1NF）**：数据库表中的每一列都是不可分割的原子数据项
- **第二范式（2NF）**：非主属性必须完全依赖于主键
- **第三范式（3NF）**：任何非主属性不依赖于其他非主属性，消除传递依赖
- **巴斯-科德范式（BCNF）**：每个非主属性不仅依赖于主键，还必须依赖于整个主键的每一个部分
- **第四范式（4NF）**：消除多值依赖，确保每个非主属性只依赖于主键，而不是其他非主属性
- **第五范式（5NF）**：消除连接依赖，确保每个非主属性只依赖于主键，而不是其他非主属性的组合

实际开发中一般满足到**第三范式**或者**巴斯范式**即可。

> 反范式化：遵循业务优先的原则，增加冗余字段，在实际开发过程中根据需要把某些经常需要查询的数据加入表中，用空间换时间，避免频繁关联查询降低性能。
>
> - 为满足某种商业目标 , 数据库性能比规范化数据库更重要
> - 在数据规范化的同时 , 要综合考虑数据库的性能
> - 通过在给定的表中添加额外的字段，以大量减少需要从中搜索信息所需的时间
> - 通过在给定的表中插入计算列，以方便查询



## 2.3、数据库调优的维度和步骤

<img src="http://jason243.online/DatabasesNote/MySQL/codinglin_mysql_notes/MySQL索引及调优篇.assets/image-20220627164114562.png" alt="image-20220627164114562" style="float:left;" />

- #### 第1步：选择适合的 DBMS

- #### 第2步：优化表设计

- #### 第3步：优化逻辑查询

- #### 第4步：添加合适索引

- #### 第5步：优化物理查询

- #### 第6步：使用 Redis 或 Memcached 作为缓存

- #### 第7步：库级优化

  - 读写分离
  - 数据分片
    - 垂直拆分（分库）
    - 水平拆分（分表）
    - 分库分表
  - 冷热数据分离
  - 增加中间表
  - 增加冗余字段
  - 优化数据类型
    - 整数类型满足范围越小越好
    - 整数类型可以满足的情况下优先用整数类型
    - 避免使用TEXT、BLOB类型，他们排序时无法使用内存临时表
    - 避免使用ENUM类型，ORDER BY效率低，可以用TINYINT替代
    - 优先用TIMESTAMP存储时间
    - 用DECIMAL存储精确浮点数
  - 使用非空约束
    - 省去判断是否为NULL的开销
    - 节省标记NULL的空间（标记一个NULL需要1bit）
  - 限定查询范围

- #### 第8步：优化系统配置（调整合适参数）

- #### 第9步：提高硬件水平



# 3、事务相关问题

## 3.1、事务的ACID特性

- **原子性（atomicity）：**原子性是指事务是一个不可分割的工作单位，要么全部提交，要么全部失败回滚。
- **一致性（consistency）：**一致性是指事务执行前后，数据从一个 `合法性状态` 变换到另外一个 `合法性状态`，例如，A账户有200余额，转账300元出去，还剩-100元，我们要求余额>=0，此时如果执行成功前后就是不一致的。
- **隔离型（isolation）：**事务的隔离性是指一个事务的执行`不能被其他事务干扰`。
- **持久性（durability）：**持久性是指一个事务一旦被提交，它对数据库中数据的改变就是 永久性的 。

> ACID是事务的四大特征，在这四个特性中，原子性是基础，隔离性是手段，一致性是约束条件， 而持久性是我们的目的。
>
> 数据库事务，其实就是数据库设计者为了方便起见，把需要保证`原子性`、`隔离性`、`一致性`和`持久性`的一个或多个数据库操作称为一个事务。



## 3.2、数据库并发会出现的问题

- **脏写**（Dirty Write）：`A` **修改** 了`B`刚刚`update`但没有`commit`的数据。
- **脏读**（Dirty Read）：`A` **读到** 了`B`刚刚`update`但没有`commit`的数据。
- **不可重复读**（Non-Repeatable Read）：`A`第一次与第二次读取时间间隔内`B`对数据进行了update，**两次读统一数据值不同**。
- **幻读**（Phantom）：`A`第一次与第二次读取时间间隔内`B`对数据进行了insert，**第二次读到了第一次没读到的数据**。

> 问题严重性：
>
> ```txt
> 脏写 > 脏读 > 不可重复读 > 幻读
> ```



## 3.3、SQL中的四种隔离级别

> 四种隔离级别都可以解决脏写

- `READ UNCOMMITTED` ：读未提交，在该隔离级别，所有事务都可以看到其他未提交事务的执行结果。**解决脏写**，不能避免脏读、不可重复读、幻读。

- `READ COMMITTED` ：读已提交，事务只能看见已经提交事务所做的改变。这是大多数数据库系统的默认隔离级别（但不是MySQL默认的）。**解决脏写、脏读**，但不可重复读、幻读问题仍然存在。

- `REPEATABLE READ` ：可重复读，事务A在读到一条数据之后，此时事务B对该数据进行了修改并提交，那么事务A再读该数据，读到的还是原来的内容。**解决脏写、脏读、不可重复读**，但幻读问题仍然存在。**这是MySQL的默认隔离级别**。

  > MySQL是可重复读隔离级别，但是通过MVCC（多版本并发控制）解决了幻读（部分解决）的问题。
  >
  > - 注：这里可以说是部分解决，即解决的显式幻读，两次select不会读取到额外的数据，但是隐式幻读没有解决，两次insert会报错，主键已存在，因为insert相当于先要隐式的调用select查一下看存数据是否存在。具体原因与MVCC的底层实现有关，只要是ReadView和undo log
  >
  > MySQL的RR隔离级别，`A`第一次 `select id = 3` 不存在，`B` `INSERT` 了 id = 3 的数据，`A` 第二次 `select` 依然是无法读取的，因为有MVCC机制，但是`A` 无法 `INSERT id = 3` ，会报错主键冲突。所以说他是部分解决了幻读的问题。

- `SERIALIZABLE` ：可串行化，确保事务可以从一个表中读取相同的行。在这个事务持续期间，禁止 其他事务对该表执行插入、更新和删除操作。所有的并发问题都可以避免，但性能十分低下。**解决脏写、脏读、不可重复读、幻读**。



## 3.4、MySQL事务日志

- REDO LOG 称为 `重做日志`，提供再写入操作，恢复提交事务修改的页操作，用来保证事务的持久性。
- UNDO LOG 称为 `回滚日志` ，回滚行记录到某个特定版本，用来保证事务的原子性、一致性。

### 3.4.1 REDO LOG 重做日志

（1）redo log是存储引擎层 (innodb) 生成的日志，记录的是`"物理级别"`上的页修改操作，比如页号xxx，偏移量yyy写入了'zzz'数据。主要为了保证数据的可靠性。



（2）redo log 的好处

- redo日志降低了刷盘频率
- redo日志占用的空间非常小，刷盘快



（3）redo log 的特点

- redo日志是顺序写入磁盘的

- 事务执行过程中，redo log不断记录



（4）redo log 的组成

- `重做日志的缓冲 (redo log buffer)` ，保存在内存中，是易失的。
- `重做日志文件 (redo log file)`，保存在硬盘中，是持久的。



（5）redo log 的整体流程

以一个更新事务为例，redo log 流转过程，如下图所示：

![image-20220710204810264](http://jason243.online/DatabasesNote/MySQL/codinglin_mysql_notes/MySQL事务篇.assets/image-20220710204810264-16574572910841.png)

```
第1步：先将原始数据从磁盘中读入内存中来，修改数据的内存拷贝
第2步：生成一条重做日志并写入redo log buffer，记录的是数据被修改后的值
第3步：当事务commit时，将redo log buffer中的内容刷新到 redo log file，对 redo log file采用追加写的方式
第4步：定期将内存中修改的数据刷新到磁盘中
```

> 体会： Write-Ahead Log(预先日志持久化)：在持久化一个数据页之前，先将内存中相应的日志页持久化。



（6）redo log 的刷盘策略与 `innodb_flush_log_at_trx_commit` 参数

> **redo log 分为两阶段提交，具体原因跟其与 binlog 的配合有关，详见 `4.2.(7)redolog的两阶段提交`** 

​	它支持三种策略：

- `设置为0` ：每次事务提交时不进行刷盘操作。（系统默认master thread每隔1s进行一次重做日 志的同步） 
- `设置为1` ：每次事务提交时都将进行同步，刷盘操作（ 默认值 ） 
- `设置为2` ：每次事务提交时都只把 redo log buffer 内容写入 page cache，不进行同步。由os自己决定什么时候同步到磁盘文件。

> 也就是说，一个没有提交事务的`redo log`记录，也可能会刷盘。因为在事务执行过程 redo log 记录是会写入 `redo log buffer`中，这些redo log 记录会被`后台线程（应该就是上面提到的master thread）`刷盘。

> 除了后台线程每秒`1次`的轮询操作，还有一种情况，当`redo log buffer`占用的空间即将达到`innodb_log_buffer_size`（这个参数默认是16M）的一半的时候，后台线程会主动刷盘。



（7）redo log 的循环写入

在整个日志文件组中还有两个重要的属性，分别是 write pos、checkpoint

- `write pos`是当前记录的位置，一边写一边后移
- `checkpoint`是当前要擦除的位置，也是往后推移

每次刷盘 redo log 记录到日志文件组中，write pos 位置就会后移更新。每次MySQL加载日志文件组恢复数据时，会清空加载过的 redo log 记录，并把check point后移更新。write pos 和 checkpoint 之间的还空着的部分可以用来写入新的 redo log 记录。

<img src="http://jason243.online/DatabasesNote/MySQL/codinglin_mysql_notes/MySQL事务篇.assets/image-20220711152631108.png" alt="image-20220711152631108" style="zoom:80%;" />

如果 write pos 追上 checkpoint ，表示`日志文件组`满了，这时候不能再写入新的 redo log记录，MySQL 得 停下来，清空一些记录，把 checkpoint 推进一下。

<img src="http://jason243.online/DatabasesNote/MySQL/codinglin_mysql_notes/MySQL事务篇.assets/image-20220711152802294.png" alt="image-20220711152802294" style="zoom:80%;" />



### 3.4.2 UNDO LOG 回滚日志

（1）undo log是存储引擎层 (innodb) 生成的日志，记录的是 `逻辑操作` 日志。主要用于 `事务的回滚` (undo log 记录的是每个修改操作的 `逆操作`) 和 `一致性非锁定读` (undo log 回滚行记录到某种特定的版本——MVCC，即多版本并发控制)。



（2）undo log 的作用

- 作用1：回滚数据
- 作用2：MVCC
  - undo的另一个作用是MVCC，即在InnoDB存储引擎中MVCC的实现是通过undo来完成。当用户读取一行记录时，若该记录以及被其他事务占用，当前事务可以通过undo读取之前的行版本信息，以此实现非锁定读取。



（3）回滚段与undo页

- InnoDB对undo log的管理采用段的方式，也就是 `回滚段（rollback segment）` 。每个回滚段记录了 `1024` 个 `undo log segment` ，而在每个undo log segment段中进行 `undo页` 的申请。

- <img src="http://jason243.online/DatabasesNote/MySQL/codinglin_mysql_notes/MySQL事务篇.assets/image-20220711155044078.png" alt="image-20220711155044078" style="float:left;" />

  简单来说就是，事务commit之后，如果undo页使用少于 3/4 时会用链表串起来，下次继续用



（4）undo的类型

- insert undo log

  insert undo log是指insert操作中产生的undo log。因为insert操作的记录，只对事务本身可见，对其他事务不可见（这是事务隔离性的要求），故该undo log可以在事务提交后直接删除。不需要进行purge操作。

- update undo log

  update undo log记录的是对delete和update操作产生的undo log。该undo log可能需要提供MVCC机制，因此不能在事务提交时就进行删除。提交时放入undo log链表，等待purge线程进行最后的删除。

> 补充：
>
> purge线程两个主要作用是：`清理undo页`和`清理page里面带有Delete_Bit标识的数据行`。在InnoDB中，事务中的Delete操作实际上并不是真正的删除掉数据行，而是一种Delete Mark操作，在记录上标识Delete_Bit，而不删除记录。是一种“假删除”，只是做了个标记，真正的删除工作需要后台purge线程去完成。



## 3.5、MVCC 多版本并发控制

（1）认识 MVCC

<img src="http://jason243.online/DatabasesNote/MySQL/codinglin_mysql_notes/MySQL事务篇.assets/image-20220711202206405.png" alt="image-20220711202206405" style="float:left;" />



（2）快照读与当前读

- 快照读：没加锁的 `SELECT` 都属于快照读，快照读又叫一致性读。
- 当前读：读取的是数据的最新版本，读取时要保证其他并发事务**不能修改当前记录**。



（3）MVCC实现原理之ReadView

**MVCC 的实现依赖于：`隐藏字段`、`Undo Log`、`Read View`。**

这个ReadView中主要包含4个比较重要的内容，分别如下：

1. `creator_trx_id` ，创建这个 Read View 的事务 ID。

   > 说明：只有在对表中的记录做改动时（执行INSERT、DELETE、UPDATE这些语句时）才会为 事务分配事务id，否则在一个只读事务中的事务id值都默认为0。

2. `trx_ids` ，表示在生成ReadView时当前系统中活跃的读写事务的 `事务id列表` 。

3. `up_limit_id` ，活跃的事务中最小的事务 ID。

4. `low_limit_id` ，表示生成ReadView时系统中应该分配给下一个事务的 id 值。low_limit_id 是系 统最大的事务id值，这里要注意是系统中的事务id，需要区别于正在活跃的事务ID。

   > 注意：low_limit_id并不是trx_ids中的最大值，事务id是递增分配的。比如，现在有id为1， 2，3这三个事务，之后id为3的事务提交了。那么一个新的读事务在生成ReadView时， trx_ids就包括1和2，up_limit_id的值就是1，low_limit_id的值就是4。



（4）ReadView判断规则：

1. **自身事务版本**：如果版本的`trx_id`等于`ReadView`中的`creator_trx_id`，说明是当前事务自己修改的版本，可以访问。
2. **已提交版本**：如果版本的`trx_id`小于`ReadView`中的`up_limit_id`，说明生成该版本的事务在`ReadView`创建前已提交，可以访问。
3. **未开始事务版本**：如果版本的`trx_id`大于或等于`ReadView`中的`low_limit_id`，说明生成该版本的事务在`ReadView`创建后才开启，不可访问。
4. **活跃事务版本**：
   - 如果版本的`trx_id`在`up_limit_id`和`low_limit_id`之间，且在`trx_ids`列表中，说明生成该版本的事务在`ReadView`创建时仍活跃，不可访问。
   - 如果版本的`trx_id`在`up_limit_id`和`low_limit_id`之间，但不在`trx_ids`列表中，说明生成该版本的事务在`ReadView`创建时已提交，可以访问。



（5）InnoDB对幻读的解决过程

接下来说明InnoDB 是如何解决幻读的。

假设现在表 student 中只有一条数据，数据内容中，主键 id=1，隐藏的 trx_id=10，它的 undo log 如下图所示。

<img src="http://jason243.online/DatabasesNote/MySQL/codinglin_mysql_notes/MySQL事务篇.assets/image-20220715141002035.png" alt="image-20220715141002035" style="zoom:80%;" />

假设现在有事务 A 和事务 B 并发执行，`事务 A` 的事务 id 为 `20` ， `事务 B` 的事务 id 为 `30` 。

步骤1：事务 A 开始第一次查询数据，查询的 SQL 语句如下。

```mysql
select * from student where id >= 1;
```

在开始查询之前，MySQL 会为事务 A 产生一个 ReadView，此时 ReadView 的内容如下： `trx_ids= [20,30] ， up_limit_id=20 ， low_limit_id=31 ， creator_trx_id=20` 。

由于此时表 student 中只有一条数据，且符合 where id>=1 条件，因此会查询出来。然后根据 ReadView 机制，发现该行数据的trx_id=10，小于事务 A 的 ReadView 里 up_limit_id，这表示这条数据是事务 A 开启之前，其他事务就已经提交了的数据，因此事务 A 可以读取到。

结论：事务 A 的第一次查询，能读取到一条数据，id=1。

步骤2：接着事务 B(trx_id=30)，往表 student 中新插入两条数据，并提交事务。

```mysql
insert into student(id,name) values(2,'李四');
insert into student(id,name) values(3,'王五');
```

此时表student 中就有三条数据了，对应的 undo 如下图所示：

![image-20220715141208667](http://jason243.online/DatabasesNote/MySQL/codinglin_mysql_notes/MySQL事务篇.assets/image-20220715141208667.png)

步骤3：接着事务 A 开启第二次查询，根据可重复读隔离级别的规则，此时事务 A 并不会再重新生成 ReadView。此时表 student 中的 3 条数据都满足 where id>=1 的条件，因此会先查出来。然后根据 ReadView 机制，判断每条数据是不是都可以被事务 A 看到。

1）首先 id=1 的这条数据，前面已经说过了，可以被事务 A 看到。 

2）然后是 id=2 的数据，它的 trx_id=30，此时事务 A 发现，这个值处于 up_limit_id 和 low_limit_id 之 间，因此还需要再判断 30 是否处于 trx_ids 数组内。由于事务 A 的 trx_ids=[20,30]，因此在数组内，这表 示 id=2 的这条数据是与事务 A 在同一时刻启动的其他事务提交的，所以这条数据不能让事务 A 看到。

3）同理，id=3 的这条数据，trx_id 也为 30，因此也不能被事务 A 看见。

![image-20220715141243993](http://jason243.online/DatabasesNote/MySQL/codinglin_mysql_notes/MySQL事务篇.assets/image-20220715141243993.png)

结论：最终事务 A 的第二次查询，只能查询出 id=1 的这条数据。这和事务 A 的第一次查询的结果是一样 的，因此没有出现幻读现象，所以说在 MySQL 的可重复读隔离级别下，不存在幻读问题。



## 3.6、MySQL的锁

<img src="http://jason243.online/DatabasesNote/MySQL/codinglin_mysql_notes/MySQL事务篇.assets/image-20220711203519162.png" alt="image-20220711203519162" style="zoom:80%;" />

> 读锁/共享锁（Shared Lock）也称为 S 锁
>
> 写锁/排它锁（Exclusive lock）也称为 X 锁



①颗粒度划分的介绍

- 行锁：只有`InnoDB`支持

  - 记录锁（Record Locks）：基本 S、X 行级锁

  - 间隙锁（Gap Locks）：用来辅助实现`可重复读`隔离级别下的**锁方式**幻读问题的解决。

    - InnoDB解决幻读问题可以通过 `MVCC` 或者 `加锁`，加锁的问题在于第一次读取的时候 `幻影数据` 并不存在，无法加记录锁，所以 InnoDB 引入间隙锁来解决这一问题。

    - 间隙锁不允许不允许在加锁行与改行的前一行数据之间添加数据（如下图，横着是列，竖着是行），如果想加在最后一行上可以加给Supernum最大记录。

      ![image-20220713171650888](http://jason243.online/DatabasesNote/MySQL/codinglin_mysql_notes/MySQL事务篇.assets/image-20220713171650888.png)

    - 不同的事务可以对同一个位置上间隙锁，比如事务A和B都对 `id = 5` 的位置上锁

  - 临键锁（Next-Key Locks）：临键锁是记录锁与间隙锁的结合，锁住当前数据和间隙

- 表锁：MySQL基本锁策略，不依赖存储引擎，开销最小（颗粒度较大），可以避免死锁，并发率大打折扣

  - 基本 S表锁、X表锁

  - 意向锁：意向锁是一种表锁，由引擎自己维护。意向锁的作用是告诉其他事务当前表被上了行锁，避免其他事物遍历寻找是否有行锁。意向锁只是一种标记，不会互斥，获取不同行的行锁可以对同一张表上意向锁（可以理解为计数引用）。

    - 意向共享锁（intention shared lock, IS）：事务有意向对表中的某些行加**共享锁**（S锁）
    - 意向排他锁（intention exclusive lock, IX）：事务有意向对表中的某些行加**排他锁**（X锁）

  - 自增锁（AUTO-INC锁）：用来解决AUTO_INCREMENT字段的自增，在单条插入、批量插入和混合插入的时候都会自动获取自增锁，确保自增对象正确赋值。显然这种表锁会造成性能下降，MySQL通过`innodb_autoinc_lock_mode` 值设定自增锁的三种模式：

    - `innodb_autoinc_lock_mode = 0(“传统”锁定模式)` ：直接获取表级锁知道事务结束
    - `innodb_autoinc_lock_mode = 1(“连续”锁定模式)` ：MySQL 8.0 之前的默认模式。简单插入采用轻量的 `mutex` 锁，其他与 mode 0 一致。
    - `innodb_autoinc_lock_mode = 2(“交错”锁定模式)` ：MySQL 8.0 之后的默认模式。不使用行锁，一律使用轻量锁分配自增值，在批量、混合插入的时候主键值可能不连续，但并发性能高。

  - 元数据锁（Metadata Lock，MDL）：进行DML（数据操作语言，增删改查）操作时加S锁，进行DDL（数据定义语言，改动表结构）操作时加写锁。

    <img src="http://jason243.online/DatabasesNote/MySQL/codinglin_mysql_notes/MySQL事务篇.assets/image-20220713143156759.png" alt="image-20220713143156759" style="float:left;" />
  
- 页锁：开销基于表锁和行锁之间，会存在死锁的问题（行锁也有可能）。



②对锁的态度划分的介绍

- 乐观锁：适合读比较多的场景。
  - 版本号：给数据加上版本号，每次写操作版本号+1，如果再次查数据库比较版本号，如果数据库中的版本号一样或者更大就写失败。
  - 时间戳：与版本号类似，给数据加上时间戳
- 悲观锁：使用就锁住，用完再释放。适合写比较多的场景。



③对加锁方式划分的介绍

- 隐式锁：通过索引的 `trx_id` 列实现，trx_id 记录了最后操作本行数据的事务ID。
  - 对于聚簇索引，比较 trx_id 中的值，与本事务相同则进行操作，如果不相同则检查对应事务是否活跃，活跃则按照对应事务建一个X锁，自己进入等待。
  - 对于二级索引，其索引信息中没有 `trx_id` ，通过索引页面 `Page Header` 中的 `PAGE_MAX_TRX_ID` 中的值判定，`PAGE_MAX_TRX_ID` 属性表示对本页面做过改动的最大事务ID， 小于自己则表明事务已提交直接操作，大于自己就回表查看 `trx_id`。

- 显示锁：明确加锁



## 3.7、死锁

（1）**MySQL中的行锁和页锁都有可能造成死锁**



（2）产生死锁的必要条件

- **互斥**：资源（如行锁）只能被一个事务独占。
- **持有并等待**：事务在持有锁的同时请求新锁。
- **不可剥夺**：锁只能由持有的事务主动释放。
- **循环等待**：事务间形成环形依赖链。

> 死锁的关键在于：两个（或以上）的Session加锁的顺序不一致。



（3）解决死锁的方法

- **方式1：**等待，直到超时（innodb_lock_wait_timeout=50s)
  - 缺点：对于在线业务来说通常等待时间是不可以接受的
- **方式2：**使用死锁检测处理死锁程序
  - 一旦检测到回路、有死锁，这时候InnoDB存储引擎会选择`回滚undo量最小的事务`，让其他事务继续执行（`innodb_deadlock_detect=on`表示开启这个逻辑）。
  - 缺点：**对数据库性能影响大。**每个新的被阻塞的线程，都要判断是不是由于自己的加入导致了死锁，这个操作时间复杂度是O(n)。如果100个并发线程同时更新同一行，意味着要检测100*100=1万次，1万个线程就会有1千万次检测。
  - **如何解决性能消耗问题**
    - 方式1：关闭死锁检测，但意味着可能会出现大量的超时，会导致业务有损。
    - 方式2：控制并发访问的数量。比如在中间件中实现对于相同行的更新，在进入引擎之前排队，这样在InnoDB内部就不会有大量的死锁检测工作。
    - **进阶方式**：数据拆分。通过合理设计，将数据拆分成n行数据之和，则每行的并行压力都相应减小为 1/n ，数据库访问时采取主键递增的顺序访问避免拆分数据间死锁。（类似流水线）



# 4、日志、备份与架构群

## 4.1 MySQL支持的日志

- **慢查询日志**：记录所有执行时间超过long_query_time的所有查询，方便我们对查询进行优化。 默认关闭。

- **通用查询日志**：记录所有连接的起始时间和终止时间，以及连接发送给数据库服务器的所有指令， 对我们复原操作的实际场景、发现问题，甚至是对数据库操作的审计都有很大的帮助。 默认关闭。

- **错误日志**：记录MySQL服务的启动、运行或停止MySQL服务时出现的问题，方便我们了解服务器的 状态，从而对服务器进行维护。 **默认开启，无法禁止**。

  - MySQL 8.0 基于社区的广泛批评和意见，对错误日志的内容进行了大量改变

    - 采用组件架构,通过不同的组件执行日志的写入和过滤功能

    - 写入错误日志的全部信息都具有唯一的错误代码从10000开始

    - 增加了一个新的消息分类《system》用于在错误日志中始终可见的非错误但服务器状态更改事件的消息

    - 增加了额外的附加信息,例如关机时的版本信息,谁发起的关机等等

    - 两种过滤方式，Internal和Dragnet

    - 三种写入形式,经典、JSON和syseventlog

- **二进制日志**：记录所有更改数据的语句，可以用于主从服务器之间的数据同步，以及服务器遇到故 障时数据的无损失恢复。 

- **中继日志**：用于主从服务器架构中，从服务器用来存放主服务器二进制日志内容的一个中间文件。 从服务器通过读取中继日志的内容，来同步主服务器上的操作。 

- **数据定义语句日志**：记录数据定义语句执行的元数据操作。默认关闭。

除二进制日志外，其他日志都是 `文本文件` 。默认情况下，所有日志创建于 `MySQL数据目录` 中。



## 4.2 二进制日志（bin log）

（1）认识：

​		binlog即binary log，二进制日志文件，也叫作变更日志（update log）。它记录了数据库所有执行的 `DDL` 和 `DML` 等数据库更新事件的语句，但是不包含没有修改任何数据的语句（如数据查询语句select、 show等）。



（2）binlog主要应用场景：

  <img src="http://jason243.online/DatabasesNote/MySQL/codinglin_mysql_notes/MySQL日志与备份篇.assets/image-20220715161800635.png" alt="image-20220715161800635" style="zoom:100%;" />

<img src="http://jason243.online/DatabasesNote/MySQL/codinglin_mysql_notes/MySQL日志与备份篇.assets/image-20220715161842703.png" alt="image-20220715161842703" style="zoom:80%;" />

（3）大量数据使用 bin log 恢复慢的一种有效解决办法

​		二进制日志可以通过数据库的 `全量备份` 和二进制日志中保存的 `增量信息` ，完成数据库的 `无损失恢复` 。 但是，如果遇到数据量大、数据库和数据表很多（比如分库分表的应用）的场景，用二进制日志进行数据恢复，是很有挑战性的，因为起止位置不容易管理。

​		在这种情况下，一个有效的解决办法是 `配置主从数据库服务器` ，甚至是 `一主多从` 的架构，把二进制日志文件的内容通过中继日志，同步到从数据库服务器中，这样就可以有效避免数据库故障导致的数据异常等问题。



（4）bin log 的写入机制

- 写入时机：事务执行过程中，先把日志写到 `binlog cache` ，事务提交的时候，再把binlog cache写到binlog文件中。

- 每个线程都分配有一块内存作为 binlog cache。

- 可以通过`binlog_cache_size`参数控制单个线程 binlog cache 大小，如果存储内容超过了这个参数，就要暂存到磁盘（Swap）。

- binlog日志刷盘流程如下：

  <img src="http://jason243.online/DatabasesNote/MySQL/codinglin_mysql_notes/MySQL日志与备份篇.assets/image-20220715172958729.png" alt="image-20220715172958729" style="zoom:80%;" />

  - write和fsync的时机，可以由参数 `sync_binlog` 控制，默认是 `0` 。
    - `sync_binlog` = 0 ：不主动刷盘，由操作系统决定。
    - `sync_binlog` = 1 ：每次提交后都刷盘
    - `sync_binlog` = N ：N次提交后刷一次盘



（5）binlog与redolog对比

- redo log 它是 `物理日志` ，记录内容是“在某个数据页上做了什么修改”，属于 InnoDB 存储引擎层产生的。
- 而 binlog 是 `逻辑日志` ，记录内容是语句的原始逻辑，类似于“给 ID=2 这一行的 c 字段加 1”，属于 MySQL Server 层。（与 redo log 配对的 undo log 也是逻辑日志）
- 虽然它们都属于持久化的保证，但是侧重点不同。
  - redo log让InnoDB存储引擎拥有了崩溃恢复能力。
  - binlog保证了MySQL集群架构的数据一致性。



（6）binlog与redolog的写入时机区别

<img src="http://jason243.online/DatabasesNote/MySQL/codinglin_mysql_notes/MySQL日志与备份篇.assets/image-20220715194959405.png" alt="image-20220715194959405" style="zoom:80%;" />



（7）redo log 的两阶段提交

- 原因：如果一次性提交redo log（像上图那样），存储引擎先写入 redo log 再写入数据，commit之后才一次性写入 binlog，如果一次性提交，在刷盘binlog之前服务器宕机，会造成主节点用 redo log 恢复有新写入的数据，从节点通过 binlog 复制的时候没有新数据

- 为了解决两份日志之间的逻辑一致问题，InnoDB存储引擎使用**两阶段提交**方案。原理很简单，将redo log的写入拆成了两个步骤prepare和commit，这就是**两阶段提交**。

  ![image-20220715195635196](http://jason243.online/DatabasesNote/MySQL/codinglin_mysql_notes/MySQL日志与备份篇.assets/image-20220715195635196.png)

  使用两阶段提交后，写入binlog时发生异常也不会有影响，因为MySQL根据redo log日志恢复数据时，发现redo log还处于prepare阶段，并且没有对应binlog日志，就会回滚该事务。

  > 另一个场景，redo log设置commit阶段发生异常，那会不会回滚事务呢？
  >
  > ![image-20220715200321717](http://jason243.online/DatabasesNote/MySQL/codinglin_mysql_notes/MySQL日志与备份篇.assets/image-20220715200321717.png)
  >
  > 并不会回滚事务，它会执行上图框住的逻辑，虽然redo log是处于prepare阶段，但是能通过事务id找到对应的binlog日志，所以MySQL认为是完整的，就会提交事务恢复数据。



## 4.3 中继日志（relay log）

- 认识：**中继日志只在主从服务器架构的从服务器上存在**。从服务器为了与主服务器保持一致，要从主服务器读取二进制日志的内容，并且把读取到的信息写入 `本地的日志文件` 中，这个从服务器本地的日志文件就叫 `中继日志` 。然后，从服务器读取中继日志，并根据中继日志的内容对从服务器的数据进行更新，完成主 从服务器的 数据同步 。



## 4.4 主从复制

（1）主从复制的作用

- 读写分离
- 数据备份
- 具有高可用性



（2）主从复制的原理：**三个线程**

​		实际上主从同步的原理就是基于 binlog 进行数据同步的。在主从复制过程中，会基于 `3 个线程` 来操 作，一个主库线程，两个从库线程。

![image-20220715215944767](http://jason243.online/DatabasesNote/MySQL/codinglin_mysql_notes/MySQL日志与备份篇.assets/image-20220715215944767.png)

- `二进制日志转储线程` （Binlog dump thread）是一个主库线程。当从库线程连接的时候， 主库可以将二进 制日志发送给从库，当主库读取事件（Event）的时候，会在 Binlog 上 `加锁` ，读取完成之后，再将锁释放掉。

- `从库 I/O 线程` 会连接到主库，向主库发送请求更新 Binlog。这时从库的 I/O 线程就可以读取到主库的二进制日志转储线程发送的 Binlog 更新部分，并且拷贝到本地的中继日志 （Relay log）。

- `从库 SQL 线程` 会读取从库中的中继日志，并且执行日志中的事件，将从库中的数据与主库保持同步。



（3）主从复制的基本原则

- 每个 `Slave` 只有一个 `Master`
- 每个 `Slave` 只能有一个唯一的服务器ID
- 每个 `Master` 可以有多个 `Slave`



（4）同步数据一致性问题

1、**主从同步的要求：**

- 读库和写库的数据一致(最终一致)； 
- 写数据必须写到写库； 
- 读数据必须到读库(不一定)；



2、主从延迟的原因

- 网络延迟
- 从库消费中继日志（relay log）的速度，比主库生产binlog的速度要慢



3、减少主从延迟的方法

① 降低多线程大事务并发的概率，优化业务逻辑 

② 优化SQL，避免慢SQL， `减少批量操作` ，建议写脚本以update-sleep这样的形式完成。 

③ `提高从库机器的配置` ，减少主库写binlog和从库读binlog的效率差。 

④ 尽量采用 `短的链路` ，也就是主库和从库服务器的距离尽量要短，提升端口带宽，减少binlog传输的网络延时。 

⑤ 实时性要求的业务读强制走主库，从库只做灾备，备份。



4、**如何解决一致性问题**

- 异步复制：数据一致性最弱

  ![image-20220718144410731](http://jason243.online/DatabasesNote/MySQL/codinglin_mysql_notes/MySQL日志与备份篇.assets/image-20220718144410731.png)

- 半同步复制：等待至少有1台从服务器完成复制（参数控制，默认为1）

  ![image-20220718144958357](http://jason243.online/DatabasesNote/MySQL/codinglin_mysql_notes/MySQL日志与备份篇.assets/image-20220718144958357.png)

- 组复制（组复制技术，简称 MGR，MySQL Group Replication）

  - 将多个节点共同组成一个复制组，在 `执行读写（RW）事务` 的时候，需要通过一致性协议层 （Consensus 层）的同意才可以提交
  - 也就是读写事务想要进行提交，必须要经过组里“大多数人”（节点数大于 N/2 + 1）的同意，，才可以进行提交
  - 针对 `只读（RO）事务` 则不需要经过组内同意，直接 COMMIT 即可。

